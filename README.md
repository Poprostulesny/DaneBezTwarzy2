# Dane bez twarzy â€” offline anonymization tool (Polish)

Projekt generuje syntetyczne dane NER dla jÄ™zyka polskiego, trenuje model NER (Flair + HerBERT),
oraz udostÄ™pnia prostÄ… funkcjÄ™ inferencyjnÄ… do anonimizacji tekstu.

## Etykiety NER (25 kategorii)

### Kategoria 1: Dane identyfikacyjne osobowe

- `{name}` â€“ imiona
- `{surname}` â€“ nazwiska
- `{age}` â€“ wiek
- `{date-of-birth}` â€“ data urodzenia
- `{date}` â€“ inne daty wydarzeÅ„ pozwalajÄ…ce identyfikowaÄ‡ osobÄ™
- `{sex}` â€“ pÅ‚eÄ‡
- `{religion}` â€“ wyznanie
- `{political-view}` â€“ poglÄ…dy polityczne
- `{ethnicity}` â€“ pochodzenie etniczne/narodowe
- `{sexual-orientation}` â€“ orientacja seksualna
- `{health}` â€“ dane o stanie zdrowia
- `{relative}` â€“ relacje rodzinne ujawniajÄ…ce toÅ¼samoÅ›Ä‡

### Kategoria 2: Dane kontaktowe i lokalizacyjne

- `{city}` â€“ miasto
- `{address}` â€“ peÅ‚ne dane adresowe
- `{email}` â€“ adresy e-mail
- `{phone}` â€“ numery telefonÃ³w

### Kategoria 3: Identyfikatory dokumentÃ³w i toÅ¼samoÅ›ci

- `{pesel}` â€“ numery PESEL
- `{document-number}` â€“ numery dokumentÃ³w

### Kategoria 4: Dane zawodowe i edukacyjne

- `{company}` â€“ nazwa pracodawcy
- `{school-name}` â€“ nazwa szkoÅ‚y
- `{job-title}` â€“ stanowisko lub funkcja

### Kategoria 5: Informacje finansowe

- `{bank-account}` â€“ numer rachunku bankowego
- `{credit-card-number}` â€“ numery kart pÅ‚atniczych

### Kategoria 6: Identyfikatory cyfrowe i loginy

- `{username}` â€“ nazwy uÅ¼ytkownikÃ³w, loginy
- `{secret}` â€“ hasÅ‚a, klucze API

---

## Instalacja

### Linux/macOS (bash)

```bash
# UtwÃ³rz i aktywuj Å›rodowisko wirtualne
python3 -m venv .venv
source .venv/bin/activate

# Zainstaluj zaleÅ¼noÅ›ci
pip install -r requirements.txt
```

### Windows (PowerShell)

```powershell
python -m venv .venv
.\.venv\Scripts\Activate.ps1
pip install -r requirements.txt
```

**Uwaga:** Instalacja `flair` moÅ¼e wymagaÄ‡ dopasowania wersji `torch` do Twojego GPU/CPU.

---

## Struktura projektu

```
DaneBezTwarzy2/
â”œâ”€â”€ config.py              # Konfiguracja: etykiety, tagi anonimizacji
â”œâ”€â”€ data_generator.py      # Generator syntetycznego korpusu NER
â”œâ”€â”€ generate_values.py     # Generator rozbudowanych plikÃ³w values.txt
â”œâ”€â”€ train.py               # Skrypt treningowy (Flair + HerBERT)
â”œâ”€â”€ anonymize.py           # ğŸ” GÅ‚Ã³wny skrypt do anonimizacji tekstu
â”œâ”€â”€ inference.py           # Funkcja anonymize(text) - stary interfejs
â”œâ”€â”€ utils.py               # Funkcje korupcji tekstu (leet-speak, typo)
â”œâ”€â”€ convert_data.py        # Konwerter zdaÅ„ z pliku Dane do mixed_templates.txt
â”œâ”€â”€ mixed_templates.txt    # Szablony zdaÅ„ z placeholderami
â”œâ”€â”€ test_data.txt          # PrzykÅ‚adowe dane do testowania anonimizacji
â”œâ”€â”€ requirements.txt       # ZaleÅ¼noÅ›ci Python
â”œâ”€â”€ Dane                   # Surowe dane ze zdaniami
â”œâ”€â”€ template_filler/       # ğŸ”„ ModuÅ‚ rekonstrukcji tekstu
â”‚   â”œâ”€â”€ __init__.py        # Eksportuje TagFiller, PolishInflector
â”‚   â”œâ”€â”€ __main__.py        # CLI: python -m template_filler
â”‚   â””â”€â”€ filler.py          # TagFiller + PolishInflector (Morfeusz2)
â””â”€â”€ data/                  # Foldery z wartoÅ›ciami i szablonami per tag
    â”œâ”€â”€ name/
    â”‚   â”œâ”€â”€ values.txt     # Lista imion
    â”‚   â””â”€â”€ templates.txt  # Szablony zdaÅ„ z {name}
    â”œâ”€â”€ surname/
    â”œâ”€â”€ city/
    â””â”€â”€ ...
```

---

## Jak generowaÄ‡ dane treningowe

### 1. Konwersja surowych danych (opcjonalnie)

JeÅ›li masz plik `Dane` z nowymi zdaniami, uruchom:

```bash
python convert_data.py
```

Konwerter wyciÄ…gnie zdania i zapisze je do `mixed_templates.txt`.

### 2. Generowanie korpusu

```bash
# Szybki test (maÅ‚y korpus)
python -c "from data_generator import generate_corpus; c=generate_corpus(n_per_template=5); print(f'train={len(c.train)}, dev={len(c.dev)}, test={len(c.test)}')"

# PeÅ‚na generacja
python data_generator.py
```

Generator:

- Wczytuje szablony z `mixed_templates.txt` i `data/*/templates.txt`
- Wczytuje wartoÅ›ci z `data/*/values.txt`
- Stosuje korupcjÄ™ tekstu (leet-speak, literÃ³wki) z prawdopodobieÅ„stwem ~25%
- Tworzy korpus Flair z podziaÅ‚em 80/10/10 (train/dev/test)

---

## Trening modelu

```bash
python train.py
```

DomyÅ›lne parametry:

- Model bazowy: `allegro/herbert-base-cased`
- Epoki: 6
- Batch size: 8
- Learning rate: 5e-5
- CRF: tak

Model zostanie zapisany w `resources/model/`.

### Parametry treningowe (opcjonalnie)

Edytuj `train.py` lub uÅ¼yj w kodzie:

```python
from train import train_model
trainer = train_model(epochs=10, model_dir="my_model")
```

---

## Anonimizacja tekstu

### Skrypt `anonymize.py`

GÅ‚Ã³wny skrypt do anonimizacji tekstu. ObsÅ‚uguje rÃ³Å¼ne tryby dziaÅ‚ania:

#### Anonimizacja tekstu z linii poleceÅ„

```bash
python anonymize.py "Jan Kowalski mieszka w Warszawie"
```

#### Anonimizacja pliku

```bash
# Anonimizacja pliku (wynik zapisze do input_anonymized.txt)
python anonymize.py -i dane.txt

# Anonimizacja z podaniem pliku wyjÅ›ciowego
python anonymize.py -i dane.txt -o anonimowe.txt

# Z wyÅ›wietlaniem szczegÃ³Å‚Ã³w wykrytych encji
python anonymize.py -i dane.txt -o anonimowe.txt -v
```

#### Anonimizacja ze standardowego wejÅ›cia

```bash
echo "MÃ³j PESEL to 90010112345" | python anonymize.py
```

#### Tryb interaktywny

```bash
python anonymize.py --interactive
```

#### RÃ³Å¼ne formaty wyjÅ›cia

```bash
# Format tekstowy (domyÅ›lny)
python anonymize.py "Jan Kowalski" --format text

# Format JSON (z encjami)
python anonymize.py "Jan Kowalski" --format json

# Format CSV
python anonymize.py "Jan Kowalski" --format csv
```

#### UÅ¼ycie wÅ‚asnego modelu

```bash
python anonymize.py -m models/custom/best-model.pt "Tekst do anonimizacji"
```

### PrzykÅ‚adowy wynik

WejÅ›cie (`test_data.txt`):

```
Nazywam siÄ™ Jan Kowalski i mieszkam w Warszawie przy ul. MarszaÅ‚kowskiej 15/3.
MÃ³j numer PESEL to 90010112345, a numer telefonu to +48 500 123 456.
```

WyjÅ›cie:

```
Nazywam siÄ™ [IMIÄ˜] [NAZWISKO] i mieszkam w [MIASTO] przy [ADRES].
MÃ³j numer PESEL to [PESEL], a numer telefonu to [TELEFON].
```

---

## Rekonstrukcja tekstu (wypeÅ‚nianie tagÃ³w)

ModuÅ‚ `template_filler` pozwala na odwrÃ³cenie procesu anonimizacji - zamienia tagi `[IMIÄ˜]`, `[MIASTO]` itd. na losowe, ale **gramatycznie poprawne** wartoÅ›ci.

### Jak dziaÅ‚a

```
Tekst oryginalny: "Jan Kowalski mieszka w Warszawie."
        â†“
Model NER (anonymize.py): wykrywa i taguje dane wraÅ¼liwe
        â†“
Tekst zanonimizowany: "Pani [IMIÄ˜] [NAZWISKO] mieszka w [MIASTO]."
        â†“
TagFiller (template_filler): wypeÅ‚nia tagi losowymi wartoÅ›ciami z odmianÄ…
        â†“
Tekst zrekonstruowany: "Pani Anna Kowalska mieszka w Krakowie."
```

### UÅ¼ycie

```bash
# Z linii poleceÅ„
python -m template_filler "Pani [IMIÄ˜] [NAZWISKO] mieszka w [MIASTO]."

# Z pliku
python -m template_filler -i anonimized.txt -o filled.txt

# W kodzie Python
from template_filler import TagFiller
filler = TagFiller()
result = filler.fill("SpotkaÅ‚em siÄ™ z [IMIÄ˜] w [MIASTO].")
# â†’ "SpotkaÅ‚em siÄ™ z Piotrem w Krakowie."
```

### Architektura

System skÅ‚ada siÄ™ z dwÃ³ch komponentÃ³w:

1. **TagFiller** - gÅ‚Ã³wna klasa wypeÅ‚niajÄ…ca tagi:

   - Losowy wybÃ³r wartoÅ›ci z `data/{tag}/values.txt`
   - Analiza kontekstu (przyimki, czasowniki) do okreÅ›lenia przypadka
   - WywoÅ‚anie Morfeusz2 do odmiany

2. **PolishInflector** - wrapper na Morfeusz2:
   - Generuje formy odmienione polskich sÅ‚Ã³w
   - Cache dla wydajnoÅ›ci
   - ObsÅ‚uguje frazy wielowyrazowe ("Zielona GÃ³ra" â†’ "Zielonej GÃ³rze")

### Wykrywanie przypadka gramatycznego

System automatycznie wykrywa wymagany przypadek na podstawie:

| Kontekst                    | Przypadek         | PrzykÅ‚ad                |
| --------------------------- | ----------------- | ----------------------- |
| w, we, na, przy             | miejscownik (loc) | "w Krakowie"            |
| do, od, z, bez, dla         | dopeÅ‚niacz (gen)  | "do Warszawy"           |
| przez                       | biernik (acc)     | "przez KrakÃ³w"          |
| z + czasownik ruchu         | dopeÅ‚niacz        | "z Krakowa przyjechaÅ‚"  |
| z + czasownik towarzyszenia | narzÄ™dnik         | "spotkaÅ‚em siÄ™ z Janem" |
| Pani, Pana                  | dopeÅ‚niacz        | "Pani Anny"             |

### WydajnoÅ›Ä‡

| Metoda                          | ZdaÅ„/sekundÄ™ | Opis                                         |
| ------------------------------- | ------------ | -------------------------------------------- |
| **TagFiller (Morfeusz2)**       | ~19 000      | âœ… Szybkie, reguÅ‚owe                         |
| HerBERT MLM (pseudo-perplexity) | ~0.5         | âŒ Wolne, kaÅ¼dy kandydat wymaga forward pass |

### Dlaczego nie uÅ¼ywamy modelu NER do predykcji wartoÅ›ci?

1. **Model NER wykrywa, nie generuje**: Nasz wytrenowany model (`final-model.pt`) to **sekwencyjny tagger** - wykrywa gdzie sÄ… dane wraÅ¼liwe i jakÄ… majÄ… kategoriÄ™. Nie jest w stanie generowaÄ‡ nowych wartoÅ›ci.

2. **Tokeny â‰  sÅ‚owa**: Model operuje na subtokenach (BPE). "Warszawa" moÅ¼e byÄ‡ rozbita na `["War", "##szaw", "##a"]`. Predykcja subtokena nie da nam sensownego sÅ‚owa.

3. **Brak mechanizmu generacji**: NER to klasyfikacja tokena (B-NAME, I-NAME, O), nie generacja tekstu. PotrzebowalibyÅ›my modelu generatywnego (GPT-like) lub MLM do uzupeÅ‚niania.

4. **Odmiana gramatyczna**: Nawet gdybyÅ›my wybrali "Warszawa", musimy jÄ… odmieniÄ‡ do "Warszawie" (miejscownik). To wymaga analizy morfologicznej (Morfeusz2), nie ML.

### Dlaczego HerBERT MLM jest wolny?

PodejÅ›cie z pseudo-perplexity wymaga:

- Dla kaÅ¼dego kandydata (np. 20 imion)
- Dla kaÅ¼dej formy odmiany (7 przypadkÃ³w)
- Dla kaÅ¼dego tokena w zdaniu (~15)
- **Forward pass przez caÅ‚y model** (110M parametrÃ³w)

To daje: 20 Ã— 7 Ã— 15 = **2100 forward passÃ³w na jedno zdanie!**

Nasze rozwiÄ…zanie z Morfeusz2 jest **~40 000x szybsze** bo:

- Losowy wybÃ³r = O(1)
- Odmiana = lookup w sÅ‚owniku morfologicznym

### Ograniczenia

1. **Obce imiona**: Morfeusz2 nie zna wszystkich imion obcych (np. "Yaroslav", "Serhii"). Takie imiona nie sÄ… odmieniane.

2. **Nazwy wÅ‚asne firm**: NiektÃ³re nazwy firm mogÄ… byÄ‡ niepoprawnie odmieniane.

3. **Kontekst semantyczny**: System nie rozumie semantyki - moÅ¼e podstawiÄ‡ mÄ™skie imiÄ™ po "Pani" (choÄ‡ gramatycznie odmieni poprawnie).

---

## Inferencja (stary interfejs)

```bash
python -c "from inference import anonymize; print(anonymize('Nazywam siÄ™ Anna Nowak i mieszkam w Krakowie.'))"
```

PrzykÅ‚adowy wynik:

```
Nazywam siÄ™ {name} {surname} i mieszkam w {city} .
```

### W kodzie Python:

```python
from inference import anonymize

text = "Jan Kowalski, lat 35, zamieszkaÅ‚y przy ul. MarszaÅ‚kowskiej 10 w Warszawie."
anonymized = anonymize(text)
print(anonymized)
# Jan Kowalski â†’ {name} {surname}
# 35 â†’ {age}
# ul. MarszaÅ‚kowskiej 10 â†’ {address}
# Warszawie â†’ {city}
```

---

## Korupcja tekstu (data augmentation)

Funkcja `corrupt_text()` w `utils.py` wprowadza realistyczne znieksztaÅ‚cenia:

- **Leet-speak:** `aâ†’@`, `oâ†’0`, `kâ†’|<`, `eâ†’3`, `sâ†’$`
- **LiterÃ³wki OCR:** `mâ†’rn`, `lâ†’1`, `nâ†’m`
- **Polskie znaki:** `Ã³â†’o`, `Å‚â†’l`
- **Losowe pominiÄ™cia i duplikacje**

PrzykÅ‚ad:

```python
from utils import corrupt_text
print(corrupt_text("Kowalski", prob=0.4))
# MoÅ¼liwy wynik: "|<0vv@l$|<i"
```

---

## Dodawanie wÅ‚asnych danych

### 1. Dodaj wartoÅ›ci

UtwÃ³rz/edytuj plik `data/{tag}/values.txt`:

```
# data/name/values.txt
Jan
Maria
Piotr
...
```

### 2. Dodaj szablony

UtwÃ³rz/edytuj plik `data/{tag}/templates.txt`:

```
# data/name/templates.txt
Moje imiÄ™ to {name}.
Pan {name} jest kierownikiem projektu.
```

### 3. Lub dodaj do mixed_templates.txt

Szablony mogÄ… zawieraÄ‡ wiele rÃ³Å¼nych tagÃ³w:

```
{name} {surname} mieszka w {city} i pracuje jako {job-title}.
```

---

## Wymagania systemowe

- Python 3.8+
- PyTorch (CPU lub CUDA)
- ~4GB RAM dla treningu (wiÄ™cej dla wiÄ™kszych korpusÃ³w)
- ~2GB na model HerBERT

---

## Pliki projektu

| Plik                | Opis                                         |
| ------------------- | -------------------------------------------- |
| `config.py`         | Konfiguracja, etykiety, przykÅ‚adowe szablony |
| `utils.py`          | Funkcje korupcji tekstu                      |
| `data_generator.py` | Generacja syntetycznego korpusu Flair        |
| `train.py`          | Skrypt treningowy (Flair + HerBERT)          |
| `inference.py`      | Funkcja `anonymize(text)`                    |
| `convert_data.py`   | Konwerter pliku Dane do mixed_templates.txt  |
| `requirements.txt`  | Lista zaleÅ¼noÅ›ci                             |

---

## Licencja

Projekt przygotowany do hackathonu. UÅ¼ycie zgodne z licencjami modelu HerBERT i biblioteki Flair.

---

## Autor

Senior ML Engineer (NLP)


# FRONTEND
cd anonymizer-ui && npm install && npm run dev